1. Vi har ett script som ger två filer: overview.csv och detailed.csv. Overview mäter precision, recall och F1 för experimentet på hela datasetet, samt F1 för varje label. Detailed återger varje textrad, hur många entiteter den innehåller och hur många entiteter modellen hittat.
2. Eftersom scriptet är genererat av ChatGPT ska jag läsa igenom det så att jag förstår det i minsta detalj
3. Med hjälp av scriptet kan vi mäta resultaten på våra experiment och jämföra dem. Vi skapar ett gemensamt google spreadsheet där vi kan skriva ner resultatet för varje experiment.
4. Vårt första experiment är att byta ut alla namn-labels mot bara NAME. Vi tror att det kommer förbättra resultatet. Ett annat experiment är att inkludera few shot examples.
5. Vi börjar med 30 rader data per experiment för att våra datorer ska orka. När vi har hittat en bra setting ökar vi mängden data. Vi bör alla jobba med samma data för att vi ska kunna jämföra resultaten.

Här är vårt spreadsheet: 
https://docs.google.com/spreadsheets/d/1SRryb4xJOOVl2xTvwc15Cf5zywOSJuQHn5MEB7T5TjA/edit?gid=220857463#gid=220857463

processen är som följer:
1. få predictions från modellen
2. kör eval_ner.py med ett run_id som speglar experimentet
3 importera resultatet från overview.csv och detailed. csv till google spreadsheet
4. ändra någon parameter och få nya predictions från modellen
5. repetera